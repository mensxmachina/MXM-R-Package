<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Introduction</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p><br>
<br>
<img src = 'https://s7.postimg.cc/wgjmt5i63/mxm_the_FBED_image_preview.png' width="500" height="1000" align="middle" />
<br>
<br> </p>

<h1>Introduction</h1>

<p>The MXM R Package, short for the latin &#39;Mens ex Machina&#39; ( Mind from the Machine ), is a collection of utility functions for feature selection, cross validation and Bayesian Networks. MXM offers many feature selection algorithms focused on providing one or more minimal feature subsets, refered also as variable signatures, that can be used to improve the performance of downstream analysis tasks such as regression and classification, by excluding irrelevant and redundant variables.</p>

<p>In this tutorial we will learn how to use the <em>Forward Backward Early Dropping (FBED)</em> algorithm. The algorithm is a variation of the usual forward selection. At every step, the most significant variable enters the selected variables set. In addition, only the significant variables stay and are further examined. The non significant ones are dropped. This goes until no variable can enter the set. The user has the option to redo this step 1 or more times (the argument K). In the end, a backward selection is performed to remove falsely selected variables.</p>

<p>For simplicity, in this tutorial, we will use a dataset referred as <strong>&ldquo;The Wine Dataset&rdquo;</strong>. </p>

<h1>Loading Data</h1>

<p><strong>The Wine Dataset</strong> contains the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample. Note that the &ldquo;Type&rdquo; variable was transformed into a categorical variable.</p>

<p>So, first of all, for this tutorial analysis, we are loading the &#39;MXM&#39; library and &#39;dplyr&#39; library for handling easier the dataset, but note that the second one is not necessary for the analysis.  </p>

<pre><code class="r">### ~ ~ ~ Load Packages ~ ~ ~ ###
library(MXM) 
library(dplyr)
</code></pre>

<p>On a next step we are downloading and opening the dataset, defining also the column names.</p>

<pre><code class="r">### ~ ~ ~ Load The Dataset ~ ~ ~ ###
wine.url &lt;- &quot;ftp://ftp.ics.uci.edu/pub/machine-learning-databases/wine/wine.data&quot;
wine &lt;- read.csv(wine.url,
                 check.names = FALSE,
                 header = FALSE) 
head(wine)
</code></pre>

<pre><code>##   V1    V2   V3   V4   V5  V6   V7   V8   V9  V10  V11  V12  V13  V14
## 1  1 14.23 1.71 2.43 15.6 127 2.80 3.06 0.28 2.29 5.64 1.04 3.92 1065
## 2  1 13.20 1.78 2.14 11.2 100 2.65 2.76 0.26 1.28 4.38 1.05 3.40 1050
## 3  1 13.16 2.36 2.67 18.6 101 2.80 3.24 0.30 2.81 5.68 1.03 3.17 1185
## 4  1 14.37 1.95 2.50 16.8 113 3.85 3.49 0.24 2.18 7.80 0.86 3.45 1480
## 5  1 13.24 2.59 2.87 21.0 118 2.80 2.69 0.39 1.82 4.32 1.04 2.93  735
## 6  1 14.20 1.76 2.45 15.2 112 3.27 3.39 0.34 1.97 6.75 1.05 2.85 1450
</code></pre>

<pre><code class="r">str(wine)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    178 obs. of  14 variables:
##  $ V1 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ V2 : num  14.2 13.2 13.2 14.4 13.2 ...
##  $ V3 : num  1.71 1.78 2.36 1.95 2.59 1.76 1.87 2.15 1.64 1.35 ...
##  $ V4 : num  2.43 2.14 2.67 2.5 2.87 2.45 2.45 2.61 2.17 2.27 ...
##  $ V5 : num  15.6 11.2 18.6 16.8 21 15.2 14.6 17.6 14 16 ...
##  $ V6 : int  127 100 101 113 118 112 96 121 97 98 ...
##  $ V7 : num  2.8 2.65 2.8 3.85 2.8 3.27 2.5 2.6 2.8 2.98 ...
##  $ V8 : num  3.06 2.76 3.24 3.49 2.69 3.39 2.52 2.51 2.98 3.15 ...
##  $ V9 : num  0.28 0.26 0.3 0.24 0.39 0.34 0.3 0.31 0.29 0.22 ...
##  $ V10: num  2.29 1.28 2.81 2.18 1.82 1.97 1.98 1.25 1.98 1.85 ...
##  $ V11: num  5.64 4.38 5.68 7.8 4.32 6.75 5.25 5.05 5.2 7.22 ...
##  $ V12: num  1.04 1.05 1.03 0.86 1.04 1.05 1.02 1.06 1.08 1.01 ...
##  $ V13: num  3.92 3.4 3.17 3.45 2.93 2.85 3.58 3.58 2.85 3.55 ...
##  $ V14: int  1065 1050 1185 1480 735 1450 1290 1295 1045 1045 ...
</code></pre>

<pre><code class="r">colnames(wine) &lt;- c(&#39;Type&#39;, &#39;Alcohol&#39;, &#39;Malic&#39;, &#39;Ash&#39;, 
                    &#39;Alcalinity&#39;, &#39;Magnesium&#39;, &#39;Phenols&#39;, 
                    &#39;Flavanoids&#39;, &#39;Nonflavanoids&#39;,
                    &#39;Proanthocyanins&#39;, &#39;Color&#39;, &#39;Hue&#39;, 
                    &#39;Dilution&#39;, &#39;Proline&#39;)
</code></pre>

<h1>FBED for Continuous</h1>

<p>For this tutorial example, we are going to apply the FBED algorithm on the above dataset, using as data and as target only continuous variables.   </p>

<h2>Selecting Appropriate Conditional Independence Test</h2>

<p>The selection of the appropriate conditional independence test is a crucial decision for the validity and success of downstream statistical analysis and machine learning tasks. Currently the __ <code>MXM R package</code>__  supports numerous tests for different combinations of <strong>target</strong> ( <em>dependent</em> ) and <strong>predictor</strong> ( <em>independent</em> ) variables. A detailed summary table to guide you through the selection of the most suitable test can be found in <strong>MXM&#39;s</strong> reference manual (p.21 <em>&ldquo;CondInditional independence tests&rdquo;</em> ). 
In our example we will use the <strong><code>MXMX::fbed.reg()</code></strong>, which is the implementation of the FBED algorithm and since we are going to examine only continuous variables, we will use the <em>Fisher&#39;s Independence Test</em>.</p>

<h2>Creating Data &amp; Target Matrices</h2>

<p><code>dataset</code> - A numeric matrix (or a <em>data.frame</em> in case of categorical predictors), containing the variables for performing the test. The rows should refer to the different samples and columns to the features. For the purposes of this example analysis, we are going to use only the continuous variables, therefore we are removing the &ldquo;Type&rdquo; variable from the dataset. Furthermore, we are removing the &ldquo;Nonflavanoids&rdquo; variable, because we will use it as target.</p>

<pre><code class="r">### ~ ~ ~ Removing The Categorical (&#39;Type&#39;) and The Target (&#39;Nonflavanoids&#39;) Variables ~ ~ ~ ###

wine_dataset &lt;- dplyr::select(wine,
                              -contains(&quot;Type&quot;),
                              -contains(&quot;Nonflavanoids&quot;)) 
head(wine_dataset)
</code></pre>

<pre><code>##   Alcohol Malic  Ash Alcalinity Magnesium Phenols Flavanoids
## 1   14.23  1.71 2.43       15.6       127    2.80       3.06
## 2   13.20  1.78 2.14       11.2       100    2.65       2.76
## 3   13.16  2.36 2.67       18.6       101    2.80       3.24
## 4   14.37  1.95 2.50       16.8       113    3.85       3.49
## 5   13.24  2.59 2.87       21.0       118    2.80       2.69
## 6   14.20  1.76 2.45       15.2       112    3.27       3.39
##   Proanthocyanins Color  Hue Dilution Proline
## 1            2.29  5.64 1.04     3.92    1065
## 2            1.28  4.38 1.05     3.40    1050
## 3            2.81  5.68 1.03     3.17    1185
## 4            2.18  7.80 0.86     3.45    1480
## 5            1.82  4.32 1.04     2.93     735
## 6            1.97  6.75 1.05     2.85    1450
</code></pre>

<p><code>target</code> -  The class variable including the values of the target variable. We should provide either a string, an integer, a numeric value, a vector, a factor, an ordered factor or a Surv object. For the purposes of this example analysis, we are going to use as the dependent variable &ldquo;Nonflavanoids&rdquo;. </p>

<pre><code class="r">wine_target &lt;- wine$Nonflavanoids
head(wine_target)
</code></pre>

<pre><code>## [1] 0.28 0.26 0.30 0.24 0.39 0.34
</code></pre>

<h2>Function&#39;s Arguments</h2>

<p>This is the first time that we are running the algorithm, so we are going to explain what each <strong>Argument</strong> refers to:</p>

<p><code>target</code> : The class variable. Provide either a string, an integer, a numeric value, a vector, a factor, an ordered factor or a Surv object. As explained above, this will be the dependent variable. If the target is a single integer value or a string, it has to corresponds to the column number or to the name of the target feature in the dataset. <em>Here</em> we choose &ldquo;Nonflavanoids&rdquo;.</p>

<p><code>dataset</code> : The dataset. Provide either a data frame or a matrix. If the dataset (predictor variables) contains missing (NA) values, they will automatically be replaced by the current variable (column) mean value with an appropriate warning to the user after the execution. <em>Here</em> we choose the whole wine dataset, except from the &ldquo;Type&rdquo; (categorical) and &ldquo;Nonflavanoids&rdquo; (target) variables.</p>

<p><code>test</code> : The conditional independence test to use. Default value is NULL. <em>Here</em> since our dataset includes only continuous features (<em>remember</em>: Categorical variable &ldquo;Type&rdquo; was removed) and our dependent variable is also continuous, we choose &#39;testIndFisher&#39;.
For more information, about which test to use, please visit :  <a href="https://www.rdocumentation.org/packages/MXM/versions/0.9.7/topics/CondInditional%20independence%20tests">https://www.rdocumentation.org/packages/MXM/versions/0.9.7/topics/CondInditional%20independence%20tests</a>. </p>

<p><code>threshold</code> : Threshold (suitable values in [0,1]) for the significance of the p-values. The default value is 0.05. <em>Here</em> we choose the default value 0.05.  </p>

<p><code>wei</code> : A vector of weights to be used for weighted regression. The default value is NULL. It is not suggested when &ldquo;robust&rdquo; is set to TRUE. If you want to use the &ldquo;testIndBinom&rdquo;, then supply the successes in the y and the trials here. <em>Here</em> we choose the default value NULL</p>

<p><code>K</code> : How many times should the process be repeated? The default value is 0. <em>Here</em> we choose 3.</p>

<p><code>method</code> : Do you want the likelihood ratio test to be performed (&ldquo;LR&rdquo; is the default value) or perform the selection using the &ldquo;eBIC&rdquo; criterion (BIC is a special case)? <em>Here</em> we choose BIC in the first example and LR for the second, in order to see the output differences.</p>

<p><code>gam</code> : In case the method chosen is &ldquo;eBIC&rdquo;, one can also specify the gamma parameter. The default value is &ldquo;NULL&rdquo;, so that the value is automatically calculated. <em>Here</em>, although we choose BIC as selection criterion, we do not choose any gamma parameter.</p>

<p><code>backward</code> : After the Forward Early Dropping phase, the algorithm proceeds with the usual Backward Selection phase. The default value is set to TRUE. It is advised to perform this step since some variables may be false positives and were wrongly selected. The backward phase using Likelihood Ratio test and eBIC are two different functions and can be called directly by the user. So, if you want for example to perform a backward regression with a different threshold value, just use these two functions separately. <em>Here</em> we set the backward argument as TRUE.</p>

<h2>Testing with eBIC</h2>

<pre><code class="r">### ~ ~ ~ Running FBED with eBIC ~ ~ ~ ###
fbed_cont_eBIC &lt;- MXM::fbed.reg(target     = wine_target,
                                 dataset   = wine_dataset, 
                                 test      = &quot;testIndFisher&quot;, 
                                 threshold = 0.05,
                                 wei       = NULL,
                                 K         = 10,
                                 method    = &quot;eBIC&quot;,
                                 gam       = NULL,
                                 backward  = TRUE)
</code></pre>

<h2>Testing with LR</h2>

<pre><code class="r">### ~ ~ ~ Running FBED with LR ~ ~ ~ ###
fbed_cont_LR &lt;- MXM::fbed.reg(target       = wine_target,
                                 datase    = wine_dataset, 
                                 test      = &quot;testIndFisher&quot;, 
                                 threshold = 0.05,
                                 wei       = NULL,
                                 K         = 10,
                                 method    = &quot;LR&quot;,
                                 gam       = NULL,
                                 backward  = TRUE)
</code></pre>

<p>So, the algorithm run twice&hellip;
Let&#39;s see what information we can take out of it. </p>

<h2>Comparing Outputs</h2>

<p>The main purpose of running FBED algorithm is to see which variables should be selected as important. The indices of those variables are stored in <code>res</code>. Furthermore, in this matrix we see their test statistic and the associated p-value.  </p>

<pre><code class="r">### ~ ~ ~ eBIC results ~ ~ ~ ###
fbed_cont_eBIC$res
</code></pre>

<pre><code>##      Vars eBIC difference
## [1,]    7       -240.5425
## [2,]    3       -280.7062
## [3,]    5       -291.0249
</code></pre>

<pre><code class="r">SelectedVars_names&lt;-colnames(wine_dataset[fbed_cont_eBIC$res[,1]])
SelectedVars_names
</code></pre>

<pre><code>## [1] &quot;Flavanoids&quot; &quot;Ash&quot;        &quot;Magnesium&quot;
</code></pre>

<p>From eBIC, we get as significant the variables &ldquo;Flavanoids&rdquo;, &ldquo;Ash&rdquo; and &ldquo;Magnesium&rdquo;, while from LR &hellip; </p>

<pre><code class="r">### ~ ~ ~ LR results ~ ~ ~ ###
fbed_cont_LR$res
</code></pre>

<pre><code>##   sel     stat       pval
## 1   7 3.681241  -8.077634
## 3   3 4.847999 -12.795188
## 4   5 4.107912  -9.694011
## 5  11 2.087806  -3.262599
</code></pre>

<pre><code class="r">SelectedVars_names&lt;-colnames(wine_dataset[fbed_cont_LR$res[,1]])
SelectedVars_names
</code></pre>

<pre><code>## [1] &quot;Flavanoids&quot; &quot;Ash&quot;        &quot;Magnesium&quot;  &quot;Dilution&quot;
</code></pre>

<p>&hellip; we get the three previous variables, plus the variable &ldquo;Dilution&rdquo;. So, the two testing approaches do not differ so much. In this case, the eBIC criterion applied a more strict feature selection, by selecting only 3 variables, while LR returned one variable more.</p>

<p>Since the function returns the variables sorted by their significance, we can easily see that the three variables chosen by both approaches are the most important. So, it depends on the initial question and dataset used to say whether the fourth variable should be used in the downstream analysis. </p>

<p>And as you may imagine, you may also retrieve the information about the scores. They are all (sorted) in the second column. </p>

<pre><code class="r">fbed_cont_eBIC$res[,2]
</code></pre>

<pre><code>## [1] -240.5425 -280.7062 -291.0249
</code></pre>

<pre><code class="r">fbed_cont_LR$res[,2]
</code></pre>

<pre><code>##        1        3        4        5 
## 3.681241 4.847999 4.107912 2.087806
</code></pre>

<p>Perfect! But we see that the function returned an object called <code>info</code>. What is this?  </p>

<pre><code class="r">fbed_cont_eBIC$info
</code></pre>

<pre><code>##     Number of vars Number of tests
## K=0              2              20
## K=1              3              10
## K=2              4               9
## K=3              4               8
</code></pre>

<pre><code class="r">fbed_cont_LR$info
</code></pre>

<pre><code>##     Number of vars Number of tests
## K=0              2              19
## K=1              4              13
## K=2              5               8
## K=3              5               7
</code></pre>

<p>The <code>info</code> matrix describes the number of variables and the number of tests performed (or models fitted) at each round (remember this value of <code>K</code> that in this example we set equal to 10? <em>Here</em> it did not reach K=10 neither with eBIC nor with LR. This happened because there were no difference after the 4th (eBIC) or 3rd (LR) run, so the algorithm stopped running earlier). We see that that LR applied one iteration less. For each <code>K</code> the number of selected variables is returned together with the number of tests performed. Therefore, we see that in the first step, 3 variables were already chosen by LR. </p>

<p>Well, all this refers to the forward phase only. So, if the information about the forward step is appended in the <code>info</code> matrix, where can we find information about the backward phase?</p>

<pre><code class="r">fbed_cont_eBIC$back.rem 
</code></pre>

<pre><code>## Vars 
##    4
</code></pre>

<pre><code class="r">fbed_cont_LR$back.rem 
</code></pre>

<pre><code>## Vars 
##    6
</code></pre>

<p>By calling the <code>back.rem</code>, the variables that have been removed in the backward phase are returned. We see that both approaches did not remove any &ldquo;false positive&rdquo; variable.</p>

<p>In case we are interested in the number of models that were fitted in the backward phase, all we have to do is to look for the <code>back.n.tests</code> variable.</p>

<pre><code class="r">fbed_cont_eBIC$back.n.tests 
</code></pre>

<pre><code>## [1] 7
</code></pre>

<pre><code class="r">fbed_cont_LR$back.n.tests 
</code></pre>

<pre><code>## [1] 9
</code></pre>

<p>We see that LR applied one test more during the backward phase. This is expected, since this method chose 4 variables (instead of 3 with eBIC) and all 4 have been checked.</p>

<p>But which of the both approaches was quicker applied? </p>

<pre><code class="r">fbed_cont_eBIC$runtime 
</code></pre>

<pre><code>##    user  system elapsed 
##     0.1     0.0     0.1
</code></pre>

<pre><code class="r">fbed_cont_LR$runtime 
</code></pre>

<pre><code>##    user  system elapsed 
##    0.02    0.00    0.01
</code></pre>

<p>Since the dataset is small, we do not see any special runtime difference.</p>

<h1>FBED for Categorical</h1>

<p>On this step, will apply FBED for a Categorical variable, using only eBIC.</p>

<h2>Selecting Appropriate Conditional Independence Test</h2>

<p>Since the variable is categorical - and more specific it is a factor with more than two levels (unordered) -and the features are continuous, according to <strong>MXM&#39;s</strong> reference manual (p.21 <em>&ldquo;CondInditional independence tests&rdquo;</em> ), we should use the Multinomial logistic regression ( &#39;testIndMultinom&#39; ).</p>

<h2>Creating Data &amp; Target Matrices</h2>

<p>In this step, we keep the whole dataset, in order to show how to use the algorithm also without subtracting the initial matrix.</p>

<pre><code class="r">### ~ ~ ~ Taking The Whole Dataset ~ ~ ~ ###
wine_dataset &lt;- dplyr::select(wine,
                              -contains(&quot;Type&quot;)) 
head(wine_dataset)
</code></pre>

<pre><code>##   Alcohol Malic  Ash Alcalinity Magnesium Phenols Flavanoids Nonflavanoids
## 1   14.23  1.71 2.43       15.6       127    2.80       3.06          0.28
## 2   13.20  1.78 2.14       11.2       100    2.65       2.76          0.26
## 3   13.16  2.36 2.67       18.6       101    2.80       3.24          0.30
## 4   14.37  1.95 2.50       16.8       113    3.85       3.49          0.24
## 5   13.24  2.59 2.87       21.0       118    2.80       2.69          0.39
## 6   14.20  1.76 2.45       15.2       112    3.27       3.39          0.34
##   Proanthocyanins Color  Hue Dilution Proline
## 1            2.29  5.64 1.04     3.92    1065
## 2            1.28  4.38 1.05     3.40    1050
## 3            2.81  5.68 1.03     3.17    1185
## 4            2.18  7.80 0.86     3.45    1480
## 5            1.82  4.32 1.04     2.93     735
## 6            1.97  6.75 1.05     2.85    1450
</code></pre>

<pre><code class="r">wine_target &lt;- as.factor(wine$Type)
head(wine_target)
</code></pre>

<pre><code>## [1] 1 1 1 1 1 1
## Levels: 1 2 3
</code></pre>

<h2>Setting the Arguments</h2>

<pre><code class="r">### ~ ~ ~ Running FBED For Categorical Variable with eBIC~ ~ ~ ###
fbed_categorical_eBIC &lt;- MXM::fbed.reg(target = wine_target,
                                 dataset      = wine_dataset, 
                                 test         = &quot;testIndMultinom&quot;,
                                 threshold    = 0.05,
                                 wei          = NULL,
                                 K            = 10,
                                 method       = &quot;eBIC&quot;,
                                 gam          = NULL,
                                 backward     = TRUE) 
</code></pre>

<pre><code class="r">### ~ ~ ~ Running FBED For Categorical Variable with LR~ ~ ~ ###
fbed_categorical_LR &lt;- MXM::fbed.reg(target = wine_target,
                                 dataset    = wine_dataset, 
                                 test       = &quot;testIndMultinom&quot;,
                                 threshold  = 0.05,
                                 wei        = NULL,
                                 K          = 10,
                                 method     = &quot;LR&quot;,
                                 gam        = NULL,
                                 backward   = TRUE) 
</code></pre>

<pre><code>## # weights:  18 (10 variable)
## initial  value 195.552987 
## iter  10 value 22.769414
## iter  20 value 6.859582
## iter  30 value 1.971162
## iter  40 value 1.829873
## iter  50 value 1.163934
## iter  60 value 1.129584
## iter  70 value 1.071912
## iter  80 value 1.064826
## iter  90 value 0.487277
## iter 100 value 0.477455
## final  value 0.477455 
## stopped after 100 iterations
## # weights:  15 (8 variable)
## initial  value 195.552987 
## iter  10 value 37.451958
## iter  20 value 27.927832
## iter  30 value 24.837868
## iter  40 value 23.766671
## iter  50 value 23.149697
## iter  60 value 22.993680
## iter  70 value 22.961828
## iter  80 value 22.953286
## iter  90 value 22.934465
## iter 100 value 22.929542
## final  value 22.929542 
## stopped after 100 iterations
## # weights:  15 (8 variable)
## initial  value 195.552987 
## iter  10 value 26.857767
## iter  20 value 20.694535
## iter  30 value 18.470545
## iter  40 value 18.092177
## iter  50 value 17.976798
## iter  60 value 17.841829
## iter  70 value 17.768169
## iter  80 value 17.729584
## iter  90 value 17.695714
## iter 100 value 17.660677
## final  value 17.660677 
## stopped after 100 iterations
## # weights:  15 (8 variable)
## initial  value 195.552987 
## iter  10 value 38.840089
## iter  20 value 25.181931
## iter  30 value 23.855234
## iter  40 value 23.809249
## iter  50 value 23.802273
## iter  60 value 23.800938
## iter  70 value 23.799450
## iter  80 value 23.798548
## final  value 23.798315 
## converged
## # weights:  15 (8 variable)
## initial  value 195.552987 
## iter  10 value 36.994356
## iter  20 value 24.354430
## iter  30 value 22.683756
## iter  40 value 22.163394
## iter  50 value 21.989378
## iter  60 value 21.943926
## iter  70 value 21.896838
## iter  80 value 21.886846
## iter  90 value 21.865875
## iter 100 value 21.849686
## final  value 21.849686 
## stopped after 100 iterations
</code></pre>

<p>So, the algorithm run once again&hellip;
Let&#39;s see what information we can take out of it.</p>

<h2>Comparing Outputs</h2>

<p>The main purpose of running FBED algorithm is to see which variables should be selected as  important. The indices of those variables are stored in <code>res</code>.</p>

<pre><code class="r">### ~ ~ ~ eBIC results ~ ~ ~ ###
fbed_categorical_eBIC$res
</code></pre>

<pre><code>##      Vars eBIC difference
## [1,]    7        89.71506
## [2,]    1        79.17733
## [3,]   13        91.45261
## [4,]   11        87.55535
</code></pre>

<pre><code class="r">SelectedVars_names&lt;-colnames(wine_dataset[fbed_categorical_eBIC$res[,1]])
SelectedVars_names
</code></pre>

<pre><code>## [1] &quot;Flavanoids&quot; &quot;Alcohol&quot;    &quot;Proline&quot;    &quot;Hue&quot;
</code></pre>

<p>From eBIC, we get as significant the variables &ldquo;Flavanoids&rdquo;, &ldquo;Alcohol&rdquo;, &ldquo;Proline&rdquo;, &ldquo;Hue&rdquo;, while from LR &hellip; </p>

<pre><code class="r">### ~ ~ ~ LR results ~ ~ ~ ###
fbed_categorical_LR$res
</code></pre>

<pre><code>##   sel     stat      pval
## 1   7 44.90417 -22.45209
## 2   1 34.36644 -17.18322
## 3  13 46.64172 -23.32086
## 4  11 42.74446 -21.37223
</code></pre>

<pre><code class="r">SelectedVars_names&lt;-colnames(wine_dataset[fbed_categorical_LR$res[,1]])
SelectedVars_names
</code></pre>

<pre><code>## [1] &quot;Flavanoids&quot; &quot;Alcohol&quot;    &quot;Proline&quot;    &quot;Hue&quot;
</code></pre>

<p>&hellip; exactly the same 4 variables were chosen. </p>

<p>What was stored this time in the <code>info</code> matrix?</p>

<pre><code class="r">fbed_categorical_eBIC$info
</code></pre>

<pre><code>##     Number of vars Number of tests
## K=0              4              40
## K=1              4               9
</code></pre>

<pre><code class="r">fbed_categorical_LR$info
</code></pre>

<pre><code>##     Number of vars Number of tests
## K=0              4              44
## K=1              4               9
</code></pre>

<p>As we see, both approaches needed 2 iterations. The only difference is that LR applied one test more. Well, this refers to the forward phase only and for each <code>K</code> the number of selected variables is returned together with the number of tests performed.</p>

<p>And now let us inspect the backward phase</p>

<pre><code class="r">fbed_categorical_eBIC$back.rem 
</code></pre>

<pre><code>## numeric(0)
</code></pre>

<pre><code class="r">fbed_categorical_LR$back.rem 
</code></pre>

<pre><code>## numeric(0)
</code></pre>

<p>No variable was removed during the backward steps&hellip; </p>

<pre><code class="r">fbed_categorical_eBIC$back.n.tests 
</code></pre>

<pre><code>## [1] 4
</code></pre>

<pre><code class="r">fbed_categorical_LR$back.n.tests 
</code></pre>

<pre><code>## [1] 4
</code></pre>

<p>&hellip; and both approaches fitted 4 models during the backward phase</p>

<p>And how quick has all this happened? </p>

<pre><code class="r">fbed_categorical_eBIC$runtime 
</code></pre>

<pre><code>##    user  system elapsed 
##    0.51    0.00    0.55
</code></pre>

<pre><code class="r">fbed_categorical_LR$runtime 
</code></pre>

<pre><code>##    user  system elapsed 
##    0.75    0.00    0.84
</code></pre>

<p>Really quick, since the dataset is small. </p>

<h1>FBED for more than one K</h1>

<p>In case the user wants to run the FBED algorithm for more than one K and compare the differences after each iteration, instead of calling the function with K=0, K=1, K=2 and so on, there is the possibility of running fbed.reg with K=0:2. Then, the selected variables found at K=2, K=1 and K=0 are returned. In order to make this issue more clear, we are going to apply again the example given in ??3.4, but this time we will ask from the algorithm to check K = 0:5</p>

<pre><code class="r">### ~ ~ ~ Running FBED For Many K ~ ~ ~ ###
wine_dataset &lt;- dplyr::select(wine,
                              -contains(&quot;Type&quot;),
                              -contains(&quot;Nonflavanoids&quot;)) 
wine_target &lt;- wine$Nonflavanoids
fbed_cont_eBIC_manyK &lt;- MXM::fbed.reg(target = wine_target,
                                 datase    = wine_dataset, 
                                 test      = &quot;testIndFisher&quot;, 
                                 threshold = 0.05,
                                 wei       = NULL,
                                 K         = 0:5,
                                 method    = &quot;LR&quot;,
                                 gam       = NULL,
                                 backward  = TRUE)
</code></pre>

<p>Looking inside the new object <code>fbed_cont_eBIC_manyK</code>, we can find all the information about each K separately. This information is stored in <code>$mod</code>, for example: </p>

<pre><code class="r">### ~ ~ ~ statistics about K=1 ~ ~ ~ ###
fbed_cont_eBIC_manyK$mod$`K=1`
</code></pre>

<pre><code>##   Vars     stat log p-value
## 1    7 8.237141  -30.806059
## 3    3 5.039103  -13.658441
## 4    5 3.870023   -8.778607
</code></pre>

<h1>Conclusion</h1>

<blockquote>
<p>Now you are ready to run your own analysis using MXM::FBED algorithm!<br/>
Thank you for your attention.<br/>
Hope that you found this tutorial helpful.    </p>
</blockquote>

<h1>Session Info {.unnumbered}</h1>

<p>All analyses have been applied on:</p>

<pre><code class="r">sessionInfo()
</code></pre>

<pre><code>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17134)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=C                  LC_CTYPE=Greek_Greece.1253   
## [3] LC_MONETARY=Greek_Greece.1253 LC_NUMERIC=C                 
## [5] LC_TIME=Greek_Greece.1253    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] dplyr_0.8.1 MXM_1.4.4  
## 
## loaded via a namespace (and not attached):
##  [1] Rfast2_0.0.2        tidyselect_0.2.5    xfun_0.7           
##  [4] slam_0.1-45         sets_1.0-18         purrr_0.3.2        
##  [7] splines_3.6.0       lattice_0.20-38     htmltools_0.3.6    
## [10] survival_2.44-1.1   rlang_0.3.4         R.oo_1.22.0        
## [13] nloptr_1.2.1        pillar_1.4.0        glue_1.3.1         
## [16] R.utils_2.8.0       RcppZiggurat_0.1.5  foreach_1.4.4      
## [19] R.cache_0.13.0      stringr_1.4.0       MatrixModels_0.4-1 
## [22] bdsmatrix_1.3-3     R.methodsS3_1.7.1   visNetwork_2.0.6   
## [25] htmlwidgets_1.3     codetools_0.2-16    evaluate_0.13      
## [28] geepack_1.2-1       coxme_2.2-10        knitr_1.22         
## [31] SparseM_1.77        doParallel_1.0.14   parallel_3.6.0     
## [34] quantreg_5.38       Rfast_1.9.4         Rcpp_1.0.1         
## [37] relations_0.6-8     jsonlite_1.6        R.rsp_0.43.1       
## [40] lme4_1.1-21         digest_0.6.18       stringi_1.4.3      
## [43] ordinal_2019.4-25   numDeriv_2016.8-1   grid_3.6.0         
## [46] tools_3.6.0         magrittr_1.5        tibble_2.1.1       
## [49] cluster_2.0.8       ucminf_1.1-4        bigmemory.sri_0.1.3
## [52] bigmemory_4.5.33    crayon_1.3.4        pkgconfig_2.0.2    
## [55] MASS_7.3-51.4       Matrix_1.2-17       energy_1.7-5       
## [58] iterators_1.0.10    assertthat_0.2.1    minqa_1.2.4        
## [61] R6_2.4.0            boot_1.3-22         nnet_7.3-12        
## [64] nlme_3.1-139        compiler_3.6.0
</code></pre>

<h1>References {.unnumbered}</h1>

<p>Borboudakis G. and Tsamardinos I. (2017). Forward-Backward Selection with Early Dropping. <a href="https://arxiv.org/pdf/1705.10770.pdf">https://arxiv.org/pdf/1705.10770.pdf</a></p>

</body>

</html>
